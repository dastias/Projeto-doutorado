{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dastias/Projeto-doutorado/blob/main/Codigo_Victor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGsuJw437MkX",
        "outputId": "ebb86934-2af3-46c1-c1c4-0486d4169a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydWaw2PL59lr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import pywt\n",
        "import scipy.signal as signal\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import math\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import logging\n",
        "import requests\n",
        "import zipfile\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class SignalPreprocessor:\n",
        "    \"\"\"Signal preprocessing pipeline including noise removal and transformation.\"\"\"\n",
        "\n",
        "    def __init__(self, window_size: int = 1024, overlap: float = 0.5, sampling_rate: float = 20000):\n",
        "        self.window_size = window_size\n",
        "        self.overlap = overlap\n",
        "        self.sampling_rate = sampling_rate\n",
        "\n",
        "    def remove_noise(self, signal: np.ndarray, method: str = 'wavelet') -> np.ndarray:\n",
        "        if method == 'wavelet':\n",
        "            wavelet = 'db4'\n",
        "            level = 4\n",
        "            coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
        "            thresh = np.median(np.abs(coeffs[-1]))/0.6745\n",
        "            for i in range(1, len(coeffs)):\n",
        "                coeffs[i] = pywt.threshold(coeffs[i], thresh, mode='soft')\n",
        "            return pywt.waverec(coeffs, wavelet)\n",
        "\n",
        "        elif method == 'butterworth':\n",
        "            nyquist = 0.5 * self.sampling_rate\n",
        "            low = 2.0 / nyquist\n",
        "            high = 450.0 / nyquist\n",
        "            b, a = signal.butter(4, [low, high], btype='band')\n",
        "            return signal.filtfilt(b, a, signal)\n",
        "\n",
        "    def generate_spectrogram(self, signal_data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Generate spectrogram from signal data.\"\"\"\n",
        "        f, t, Sxx = signal.spectrogram(signal_data,\n",
        "                                    fs=self.sampling_rate,\n",
        "                                    window='hann',\n",
        "                                    nperseg=self.window_size,\n",
        "                                    noverlap=int(self.window_size * self.overlap))\n",
        "\n",
        "        # Convert to dB scale and normalize\n",
        "        Sxx = 10 * np.log10(Sxx + 1e-10)\n",
        "        Sxx = (Sxx - Sxx.min()) / (Sxx.max() - Sxx.min() + 1e-10)\n",
        "        return Sxx"
      ],
      "metadata": {
        "id": "16e8-ZIuEKO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VBLVA001Dataset(Dataset):\n",
        "    \"\"\"Custom dataset for VBL-VA001 vibration data.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                data_path: str,\n",
        "                transform: Optional[transforms.Compose] = None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "        self.preprocessor = SignalPreprocessor(sampling_rate=20000)  # VBL-VA001 sampling rate is 25.6 kHz\n",
        "\n",
        "        # Load VBL-VA001 dataset\n",
        "        self.data, self.labels, self.label_mapping = self._load_vbl_va001_data()\n",
        "\n",
        "        if len(self.data) == 0:\n",
        "            raise ValueError(f\"No data was loaded from {data_path}. Please check the dataset path and structure.\")\n",
        "\n",
        "        # Get the actual number of unique classes in the dataset\n",
        "        self.num_classes = len(np.unique(self.labels))\n",
        "        logger.info(f\"Successfully loaded dataset with {len(self.data)} samples and {self.num_classes} unique classes\")\n",
        "\n",
        "    def _load_vbl_va001_data(self) -> Tuple[List, List, Dict]:\n",
        "        \"\"\"\n",
        "        Load the VBL-VA001 dataset and create dynamic mapping of available condition folders.\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        labels = []\n",
        "\n",
        "        try:\n",
        "            # Check if data path exists\n",
        "            if not os.path.exists(self.data_path):\n",
        "                logger.error(f\"Data path does not exist: {self.data_path}\")\n",
        "                return [], [], {}\n",
        "\n",
        "            # Get all subdirectories that could contain fault data\n",
        "            available_dirs = [d for d in os.listdir(self.data_path)\n",
        "                            if os.path.isdir(os.path.join(self.data_path, d))]\n",
        "            logger.info(f\"Available directories: {available_dirs}\")\n",
        "\n",
        "            # Create a new mapping based on actually available directories\n",
        "            # Sort directories to ensure consistent label assignments\n",
        "            available_dirs.sort()\n",
        "\n",
        "            conditions = {}\n",
        "            label_mapping = {}  # Store mapping for later reference\n",
        "            for i, directory in enumerate(available_dirs):\n",
        "                conditions[directory] = i\n",
        "                label_mapping[i] = directory\n",
        "                logger.info(f\"Assigned label {i} to condition: {directory}\")\n",
        "\n",
        "            if not conditions:\n",
        "                logger.error(\"No valid condition directories found!\")\n",
        "                return [], [], {}\n",
        "\n",
        "            # Process each condition directory\n",
        "            for condition, label in conditions.items():\n",
        "                condition_path = os.path.join(self.data_path, condition)\n",
        "                logger.info(f\"Processing condition: {condition}\")\n",
        "\n",
        "                # Get all CSV files for this condition\n",
        "                csv_files = [f for f in os.listdir(condition_path) if f.endswith('.csv')]\n",
        "                logger.info(f\"Found {len(csv_files)} CSV files in {condition_path}\")\n",
        "\n",
        "                # Process each CSV file (limit to 50 per condition)\n",
        "                for file in csv_files[:50]:\n",
        "                    try:\n",
        "                        file_path = os.path.join(condition_path, file)\n",
        "\n",
        "                        # Read CSV file - VBL-VA001 data format\n",
        "                        df = pd.read_csv(file_path)\n",
        "\n",
        "                        # Extract acceleration data (assuming column structure)\n",
        "                        if len(df.columns) >= 2:  # At least time and one acceleration channel\n",
        "                            # Use first acceleration column by default (column index 1)\n",
        "                            signal_data = df.iloc[:, 1].values\n",
        "\n",
        "                            # Trim signal to control memory usage\n",
        "                            max_length = 50000  # Adjust as needed\n",
        "                            if len(signal_data) > max_length:\n",
        "                                signal_data = signal_data[:max_length]\n",
        "\n",
        "                            data.append(signal_data)\n",
        "                            labels.append(label)\n",
        "                        else:\n",
        "                            logger.warning(f\"CSV file {file} does not have expected columns\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error loading file {file}: {str(e)}\")\n",
        "\n",
        "            if not data:\n",
        "                logger.error(\"No data was loaded!\")\n",
        "                return [], [], {}\n",
        "\n",
        "            # Convert labels to numpy array for easier processing\n",
        "            labels_array = np.array(labels)\n",
        "\n",
        "            # Create a mapping of original labels to consecutive integers starting from 0\n",
        "            unique_labels = np.unique(labels_array)\n",
        "            remap = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "\n",
        "            # Update label mapping\n",
        "            new_label_mapping = {}\n",
        "            for new_label, old_label in enumerate(unique_labels):\n",
        "                new_label_mapping[new_label] = label_mapping[old_label]\n",
        "\n",
        "            # Remap labels to be consecutive integers\n",
        "            remapped_labels = [remap[label] for label in labels]\n",
        "\n",
        "            logger.info(f\"Successfully loaded {len(data)} samples with remapped label distribution: {pd.Series(remapped_labels).value_counts().to_dict()}\")\n",
        "            logger.info(f\"Label mapping: {new_label_mapping}\")\n",
        "\n",
        "            return data, remapped_labels, new_label_mapping\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during data loading: {str(e)}\")\n",
        "            return [], [], {}\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
        "        signal = self.data[idx]\n",
        "\n",
        "        # Preprocess signal\n",
        "        try:\n",
        "            # Clear separation between signal denoising and spectrogram generation\n",
        "            denoised_signal = self.preprocessor.remove_noise(signal)\n",
        "            spectrogram = self.preprocessor.generate_spectrogram(denoised_signal)\n",
        "\n",
        "            # Add channel dimension for CNN\n",
        "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
        "\n",
        "            # Convert to tensor\n",
        "            spectrogram = torch.from_numpy(spectrogram).float()\n",
        "\n",
        "            if self.transform:\n",
        "                spectrogram = self.transform(spectrogram)\n",
        "\n",
        "            return spectrogram, self.labels[idx]\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing sample {idx}: {str(e)}\")\n",
        "            # Return a dummy sample for robustness\n",
        "            dummy = torch.zeros((1, 129, 129))\n",
        "            if self.transform:\n",
        "                dummy = self.transform(dummy)\n",
        "            return dummy, self.labels[idx]"
      ],
      "metadata": {
        "id": "yfGnLtJwEKMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VibrationAnalysisCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "\n",
        "        # Safety check - ensure at least 2 classes for classification\n",
        "        self.num_classes = max(2, num_classes)\n",
        "        logger.info(f\"Initializing model with {self.num_classes} output classes\")\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, self.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "J7LgbjsUEKJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLRModel(nn.Module):\n",
        "    \"\"\"Self-supervised learning model based on SimCLR architecture.\"\"\"\n",
        "\n",
        "    def __init__(self, input_shape: Tuple[int, int], projection_dim: int = 128, num_classes: int = 2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes  # Adicionando atributo num_classes\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, projection_dim)\n",
        "        )\n",
        "\n",
        "        # Adicionando classificador para fine-tuning\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, self.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        h = self.encoder(x)\n",
        "        h = h.view(h.size(0), -1)\n",
        "        z = self.projection(h)\n",
        "        return z\n",
        "\n",
        "    def forward_classifier(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Método para classificação depois do pré-treinamento\n",
        "        h = self.encoder(x)\n",
        "        h = h.view(h.size(0), -1)\n",
        "        logits = self.classifier(h)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "UYhM3C3AEJ_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRALayer(nn.Module):\n",
        "    \"\"\"Low-Rank Adaptation layer for efficient fine-tuning.\"\"\"\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int, rank: int = 4):\n",
        "        super().__init__()\n",
        "        self.lora_A = nn.Parameter(torch.zeros(in_features, rank))\n",
        "        self.lora_B = nn.Parameter(torch.zeros(rank, out_features))\n",
        "        self.scale = 0.01\n",
        "\n",
        "        # Initialize weights\n",
        "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.lora_B)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.scale * (x @ self.lora_A @ self.lora_B)"
      ],
      "metadata": {
        "id": "XkL7QK6cFQjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelAgent:\n",
        "    \"\"\"Agent for model selection and monitoring.\"\"\"\n",
        "\n",
        "    def __init__(self, models: Dict[str, nn.Module]):\n",
        "        self.models = models\n",
        "        self.performance_scores = {name: 1.0 for name in models.keys()}\n",
        "\n",
        "    def select_model(self, signal_features: Dict) -> str:\n",
        "        \"\"\"Select best model based on signal characteristics and past performance.\"\"\"\n",
        "        scores = {}\n",
        "        for name, model in self.models.items():\n",
        "            base_score = self.performance_scores[name]\n",
        "            # Add feature-based scoring here\n",
        "            scores[name] = base_score\n",
        "\n",
        "        return max(scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "    def update_performance(self, model_name: str, metric_value: float):\n",
        "        \"\"\"Update model performance scores.\"\"\"\n",
        "        alpha = 0.9  # Smoothing factor\n",
        "        self.performance_scores[model_name] = (alpha * self.performance_scores[model_name] +\n",
        "                                          (1 - alpha) * metric_value)"
      ],
      "metadata": {
        "id": "KygG0z2_FQdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VibrationAnalyzer:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.config = config\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        logger.info(f\"Using device: {self.device}\")\n",
        "        self.metrics_history = []\n",
        "        self.model = None\n",
        "        self.label_mapping = None\n",
        "\n",
        "        # Initialize model agent if multiple models are specified\n",
        "        self.model_agent = None\n",
        "        self.models = {}\n",
        "        if 'use_model_agent' in config and config['use_model_agent']:\n",
        "            logger.info(\"Initializing ModelAgent for adaptive model selection\")\n",
        "            self._initialize_models()\n",
        "\n",
        "    def _initialize_models(self):\n",
        "        \"\"\"Initialize multiple model architectures for ModelAgent.\"\"\"\n",
        "        # Initialize base CNN model\n",
        "        base_model = VibrationAnalysisCNN(num_classes=2)  # Will be updated to correct class count later\n",
        "        self.models['base_cnn'] = base_model\n",
        "\n",
        "        # Initialize SimCLR model if enabled in config\n",
        "        if 'use_simclr' in self.config and self.config['use_simclr']:\n",
        "            # Default input shape for spectrogram (can be updated later)\n",
        "            input_shape = (129, 129)\n",
        "            simclr_model = SimCLRModel(input_shape=input_shape, num_classes=2)  # Inicializar com num_classes\n",
        "            self.models['simclr'] = simclr_model\n",
        "            logger.info(\"SimCLR model initialized\")\n",
        "\n",
        "        # Create ModelAgent\n",
        "        self.model_agent = ModelAgent(self.models)\n",
        "        logger.info(f\"ModelAgent initialized with {len(self.models)} models\")\n",
        "\n",
        "    def train(self, train_loader: DataLoader, val_loader: DataLoader, num_classes: int, label_mapping: Dict = None):\n",
        "        \"\"\"Train the model with continuous monitoring.\"\"\"\n",
        "        self.label_mapping = label_mapping\n",
        "\n",
        "        # Safety check - use at least 2 classes\n",
        "        num_classes = max(2, num_classes)\n",
        "        logger.info(f\"Training model with {num_classes} classes\")\n",
        "\n",
        "        # Inspect data to determine actual classes present in the dataset\n",
        "        actual_classes = set()\n",
        "        for _, batch_targets in train_loader:\n",
        "            actual_classes.update(batch_targets.numpy())\n",
        "\n",
        "        # Adjust num_classes based on actual data\n",
        "        actual_num_classes = max(actual_classes) + 1 if actual_classes else num_classes\n",
        "        logger.info(f\"Detected {actual_num_classes} unique classes in training data, labels: {actual_classes}\")\n",
        "\n",
        "        # If model agent is enabled, update all models with correct number of classes\n",
        "        if self.model_agent:\n",
        "            for name, model in self.models.items():\n",
        "                if hasattr(model, 'num_classes'):\n",
        "                    # Update model's num_classes property\n",
        "                    model.num_classes = actual_num_classes\n",
        "\n",
        "                    # Rebuild classifier for SimCLR model with the correct number of classes\n",
        "                    if isinstance(model, SimCLRModel):\n",
        "                        model.classifier = nn.Sequential(\n",
        "                            nn.Linear(128, 256),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.5),\n",
        "                            nn.Linear(256, actual_num_classes)\n",
        "                        ).to(self.device)\n",
        "                        logger.info(f\"Rebuilt SimCLR classifier with {actual_num_classes} output classes\")\n",
        "\n",
        "                    # For VibrationAnalysisCNN, we need to rebuild the classifier\n",
        "                    elif isinstance(model, VibrationAnalysisCNN):\n",
        "                        model.classifier = nn.Sequential(\n",
        "                            nn.Linear(128, 256),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(0.5),\n",
        "                            nn.Linear(256, actual_num_classes)\n",
        "                        ).to(self.device)\n",
        "                        logger.info(f\"Rebuilt CNN classifier with {actual_num_classes} output classes\")\n",
        "\n",
        "            # Let the agent select the best model to start with\n",
        "            signal_features = {'num_classes': actual_num_classes}  # Could add more features here\n",
        "            selected_model = self.model_agent.select_model(signal_features)\n",
        "            self.model = self.models[selected_model].to(self.device)\n",
        "            logger.info(f\"ModelAgent selected '{selected_model}' for training\")\n",
        "        else:\n",
        "            # Use standard VibrationAnalysisCNN if no agent is specified\n",
        "            self.model = VibrationAnalysisCNN(num_classes=actual_num_classes).to(self.device)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.config['learning_rate'])\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "        early_stop_patience = 10\n",
        "\n",
        "        for epoch in range(self.config['epochs']):\n",
        "            try:\n",
        "                # Validate data loaders before training\n",
        "                if len(train_loader) == 0:\n",
        "                    logger.error(\"Training data loader is empty!\")\n",
        "                    break\n",
        "                if len(val_loader) == 0:\n",
        "                    logger.error(\"Validation data loader is empty!\")\n",
        "                    break\n",
        "\n",
        "                train_loss = self._train_epoch(self.model, train_loader, criterion, optimizer)\n",
        "                val_metrics = self._validate(self.model, val_loader, criterion)\n",
        "\n",
        "                # Update learning rate\n",
        "                scheduler.step(val_metrics['val_loss'])\n",
        "\n",
        "                # Update model agent scores if enabled\n",
        "                if self.model_agent:\n",
        "                    current_model_name = [name for name, model in self.models.items()\n",
        "                                        if model == self.model][0]\n",
        "                    self.model_agent.update_performance(current_model_name, val_metrics['accuracy'])\n",
        "\n",
        "                    # Potentially switch models if another is predicted to perform better\n",
        "                    if epoch > 0 and epoch % 5 == 0:  # Check every 5 epochs\n",
        "                        signal_features = {'epoch': epoch}  # Add more features as needed\n",
        "                        best_model_name = self.model_agent.select_model(signal_features)\n",
        "                        if best_model_name != current_model_name:\n",
        "                            logger.info(f\"Switching from {current_model_name} to {best_model_name} at epoch {epoch}\")\n",
        "                            self.model = self.models[best_model_name].to(self.device)\n",
        "                            # Reset optimizer and scheduler for new model\n",
        "                            optimizer = optim.Adam(self.model.parameters(),\n",
        "                                                  lr=self.config['learning_rate'])\n",
        "                            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "\n",
        "                # Early stopping\n",
        "                if val_metrics['val_loss'] < best_val_loss:\n",
        "                    best_val_loss = val_metrics['val_loss']\n",
        "                    patience_counter = 0\n",
        "                    # Save best model\n",
        "                    torch.save(self.model.state_dict(), 'best_model.pth')\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                if patience_counter >= early_stop_patience:\n",
        "                    logger.info(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                    break\n",
        "\n",
        "                # Log metrics\n",
        "                metrics = {\n",
        "                    'epoch': epoch,\n",
        "                    'train_loss': train_loss,\n",
        "                    **val_metrics\n",
        "                }\n",
        "                self.metrics_history.append(metrics)\n",
        "\n",
        "                logger.info(f\"Epoch {epoch+1}/{self.config['epochs']}: \"\n",
        "                          f\"train_loss={train_loss:.4f}, \"\n",
        "                          f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "                          f\"val_accuracy={val_metrics['accuracy']:.4f}, \"\n",
        "                          f\"lr={optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error during epoch {epoch}: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "        # Load best model for evaluation with error handling\n",
        "        if os.path.exists('best_model.pth'):\n",
        "            try:\n",
        "                self.model.load_state_dict(torch.load('best_model.pth'))\n",
        "                logger.info(\"Loaded best model for final evaluation\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error loading best model: {str(e)}\")\n",
        "                logger.info(\"Continuing with the current model state\")\n",
        "\n",
        "    # Fix 2: Enhanced train_epoch function with better error handling and target filtering\n",
        "    def _train_epoch(self, model: nn.Module,\n",
        "                  train_loader: DataLoader,\n",
        "                  criterion: nn.Module,\n",
        "                  optimizer: optim.Optimizer) -> float:\n",
        "\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "        valid_batches = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            try:\n",
        "                # Filter out samples with out-of-range target values\n",
        "                valid_indices = target < model.num_classes\n",
        "                if not torch.all(valid_indices):\n",
        "                    invalid_targets = torch.unique(target[~valid_indices]).tolist()\n",
        "                    logger.warning(f\"Batch {batch_idx}: Filtering out {(~valid_indices).sum().item()} samples with invalid targets: {invalid_targets}\")\n",
        "\n",
        "                    # Skip batch if no valid samples remain\n",
        "                    if not torch.any(valid_indices):\n",
        "                        logger.warning(f\"Skipping batch {batch_idx}: No valid targets\")\n",
        "                        continue\n",
        "\n",
        "                    # Keep only valid samples\n",
        "                    data = data[valid_indices]\n",
        "                    target = target[valid_indices]\n",
        "\n",
        "                # Move data to device\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "                # Double-check target values (defensive)\n",
        "                if torch.max(target).item() >= model.num_classes:\n",
        "                    logger.error(f\"Target values still out of range after filtering: {torch.unique(target)}\")\n",
        "                    continue\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass based on model type\n",
        "                if isinstance(model, SimCLRModel):\n",
        "                    output = model.forward_classifier(data)\n",
        "                else:\n",
        "                    output = model(data)\n",
        "\n",
        "                loss = criterion(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                num_batches += 1\n",
        "                valid_batches += 1\n",
        "\n",
        "                # Print progress every 10 batches\n",
        "                if batch_idx % 10 == 0:\n",
        "                    logger.info(f\"Train Batch {batch_idx}/{len(train_loader)}: Loss {loss.item():.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error in training batch {batch_idx}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        logger.info(f\"Completed training epoch: {valid_batches}/{len(train_loader)} valid batches processed\")\n",
        "        return total_loss / max(1, num_batches)  # Avoid division by zero\n",
        "\n",
        "        def _validate(self, model: nn.Module, val_loader: DataLoader, criterion: nn.Module) -> Dict:\n",
        "          \"\"\"Validate model and compute metrics.\"\"\"\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        valid_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(val_loader):\n",
        "                try:\n",
        "                    # Filter out samples with out-of-range target values\n",
        "                    valid_indices = target < model.num_classes\n",
        "                    if not torch.all(valid_indices):\n",
        "                        invalid_targets = torch.unique(target[~valid_indices]).tolist()\n",
        "                        logger.warning(f\"Validation batch {batch_idx}: Filtering out {(~valid_indices).sum().item()} samples with invalid targets: {invalid_targets}\")\n",
        "\n",
        "                        # Skip batch if no valid samples remain\n",
        "                        if not torch.any(valid_indices):\n",
        "                            logger.warning(f\"Skipping validation batch {batch_idx}: No valid targets\")\n",
        "                            continue\n",
        "\n",
        "                        # Keep only valid samples\n",
        "                        data = data[valid_indices]\n",
        "                        target = target[valid_indices]\n",
        "\n",
        "                    data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "                    # Double-check target values (defensive)\n",
        "                    if torch.max(target).item() >= model.num_classes:\n",
        "                        logger.error(f\"Validation target values still out of range after filtering: {torch.unique(target)}\")\n",
        "                        continue\n",
        "\n",
        "                    # Forward pass based on model type\n",
        "                    if isinstance(model, SimCLRModel):\n",
        "                        output = model.forward_classifier(data)\n",
        "                    else:\n",
        "                        output = model(data)\n",
        "\n",
        "                    val_loss += criterion(output, target).item()\n",
        "\n",
        "                    pred = output.argmax(dim=1)\n",
        "                    predictions.extend(pred.cpu().numpy())\n",
        "                    targets.extend(target.cpu().numpy())\n",
        "                    valid_batches += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error in validation batch {batch_idx}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        if valid_batches > 0:  # Avoid division by zero\n",
        "            val_loss /= valid_batches\n",
        "\n",
        "        logger.info(f\"Completed validation: {valid_batches}/{len(val_loader)} valid batches processed\")\n",
        "\n",
        "        # Compute metrics\n",
        "        if len(targets) > 0:  # Ensure we have predictions to evaluate\n",
        "            accuracy = accuracy_score(targets, predictions)\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                targets, predictions, average='weighted', zero_division=0\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'val_loss': val_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1\n",
        "            }\n",
        "        else:\n",
        "            logger.warning(\"No validation predictions generated\")\n",
        "            return {\n",
        "                'val_loss': val_loss,\n",
        "                'accuracy': 0,\n",
        "                'precision': 0,\n",
        "                'recall': 0,\n",
        "                'f1': 0\n",
        "            }\n",
        "\n",
        "    # Fix 5: Enhanced model loading functionality to handle architecture mismatches\n",
        "    def evaluate(self, test_loader: DataLoader, num_classes: int):\n",
        "        \"\"\"Evaluate model on test set and generate confusion matrix.\"\"\"\n",
        "        if self.model is None:\n",
        "            logger.error(\"Model not trained yet\")\n",
        "            return\n",
        "\n",
        "        # Ensure model is in evaluation mode\n",
        "        self.model.eval()\n",
        "        predictions = []\n",
        "        targets = []\n",
        "\n",
        "        # First check that we're using the correct model with the right number of classes\n",
        "        actual_classes = set()\n",
        "        for _, batch_targets in test_loader:\n",
        "            actual_classes.update(batch_targets.numpy())\n",
        "\n",
        "        actual_num_classes = max(actual_classes) + 1 if actual_classes else num_classes\n",
        "\n",
        "        # If there's a mismatch, update the model's classifier\n",
        "        if hasattr(self.model, 'num_classes') and self.model.num_classes != actual_num_classes:\n",
        "            logger.warning(f\"Model has {self.model.num_classes} output classes but test data has {actual_num_classes} classes\")\n",
        "            logger.info(\"Attempting to reconstruct classifier layer...\")\n",
        "\n",
        "            if isinstance(self.model, SimCLRModel):\n",
        "                self.model.num_classes = actual_num_classes\n",
        "                self.model.classifier = nn.Sequential(\n",
        "                    nn.Linear(128, 256),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(0.5),\n",
        "                    nn.Linear(256, actual_num_classes)\n",
        "                ).to(self.device)\n",
        "            elif isinstance(self.model, VibrationAnalysisCNN):\n",
        "                self.model.num_classes = actual_num_classes\n",
        "                self.model.classifier = nn.Sequential(\n",
        "                    nn.Linear(128, 256),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(0.5),\n",
        "                    nn.Linear(256, actual_num_classes)\n",
        "                ).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                try:\n",
        "                    # Filter out samples with out-of-range target values\n",
        "                    valid_indices = target < self.model.num_classes\n",
        "                    if not torch.all(valid_indices):\n",
        "                        # Keep only valid samples\n",
        "                        data = data[valid_indices]\n",
        "                        target = target[valid_indices]\n",
        "\n",
        "                        # Skip if no valid samples remain\n",
        "                        if not torch.any(valid_indices):\n",
        "                            continue\n",
        "\n",
        "                    data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "                    # Forward pass based on model type\n",
        "                    if isinstance(self.model, SimCLRModel):\n",
        "                        output = self.model.forward_classifier(data)\n",
        "                    else:\n",
        "                        output = self.model(data)\n",
        "\n",
        "                    pred = output.argmax(dim=1)\n",
        "                    predictions.extend(pred.cpu().numpy())\n",
        "                    targets.extend(target.cpu().numpy())\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error during evaluation: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        # Compute and display evaluation metrics\n",
        "        if len(targets) > 0:\n",
        "            from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "            # Get unique classes actually present in predictions and targets\n",
        "            unique_classes = sorted(set(np.concatenate([targets, predictions])))\n",
        "\n",
        "            # Generate class names for reporting\n",
        "            class_names = []\n",
        "            for i in unique_classes:\n",
        "                if self.label_mapping and i in self.label_mapping:\n",
        "                    class_names.append(self.label_mapping[i])\n",
        "                else:\n",
        "                    class_names.append(f\"Class {i}\")\n",
        "\n",
        "            # Compute confusion matrix\n",
        "            cm = confusion_matrix(targets, predictions, labels=unique_classes)\n",
        "\n",
        "            # Plot confusion matrix\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                      xticklabels=class_names, yticklabels=class_names)\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('True')\n",
        "            plt.title('Confusion Matrix - VBL-VA001 Dataset')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('confusion_matrix_vbl_va001.png')\n",
        "            plt.close()  # Close to avoid display issues\n",
        "\n",
        "            # Print classification report\n",
        "            report = classification_report(targets, predictions,\n",
        "                                  labels=unique_classes,\n",
        "                                  target_names=class_names,\n",
        "                                  zero_division=0)\n",
        "            print(\"\\nClassification Report:\")\n",
        "            print(report)\n",
        "\n",
        "            logger.info(f\"Evaluation completed on {len(targets)} samples\")\n",
        "        else:\n",
        "            logger.error(\"No test predictions generated - cannot create evaluation metrics\")\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        \"\"\"Plot training metrics history.\"\"\"\n",
        "        if not self.metrics_history:\n",
        "            logger.error(\"No metrics to plot. Train the model first.\")\n",
        "            return\n",
        "\n",
        "        metrics_df = pd.DataFrame(self.metrics_history)\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        # Plot training and validation loss\n",
        "        axes[0, 0].plot(metrics_df['epoch'], metrics_df['train_loss'], label='Train')\n",
        "        axes[0, 0].plot(metrics_df['epoch'], metrics_df['val_loss'], label='Validation')\n",
        "        axes[0, 0].set_title('Loss')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "        axes[0, 0].set_ylabel('Loss')\n",
        "        axes[0, 0].legend()\n",
        "\n",
        "        # Plot accuracy\n",
        "        axes[0, 1].plot(metrics_df['epoch'], metrics_df['accuracy'])\n",
        "        axes[0, 1].set_title('Validation Accuracy')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "        axes[0, 1].set_ylabel('Accuracy')\n",
        "\n",
        "        # Plot precision/recall\n",
        "        axes[1, 0].plot(metrics_df['epoch'], metrics_df['precision'], label='Precision')\n",
        "        axes[1, 0].plot(metrics_df['epoch'], metrics_df['recall'], label='Recall')\n",
        "        axes[1, 0].set_title('Precision and Recall')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "        axes[1, 0].legend()\n",
        "\n",
        "        # Plot F1 score\n",
        "        axes[1, 1].plot(metrics_df['epoch'], metrics_df['f1'])\n",
        "        axes[1, 1].set_title('F1 Score')\n",
        "        axes[1, 1].set_xlabel('Epoch')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_metrics_vbl_va001.png')\n",
        "        plt.show()\n",
        "\n",
        "    def train_simclr(self, train_loader: DataLoader, temperature: float = 0.5, epochs: int = 20):\n",
        "        \"\"\"Train SimCLR model with contrastive loss.\"\"\"\n",
        "        if 'simclr' not in self.models:\n",
        "            logger.error(\"SimCLR model not initialized\")\n",
        "            return\n",
        "\n",
        "        model = self.models['simclr'].to(self.device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=self.config.get('simclr_lr', 0.001))\n",
        "\n",
        "        logger.info(\"Starting SimCLR pre-training...\")\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch_idx, (data, _) in enumerate(train_loader):\n",
        "                # Generate two augmented views for each sample\n",
        "                batch_size = data.size(0)\n",
        "\n",
        "                # Simple augmentations - can be replaced with more sophisticated transforms\n",
        "                transform = transforms.Compose([\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.RandomRotation(10),\n",
        "                    transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "                ])\n",
        "\n",
        "                augmented1 = transform(data)\n",
        "                augmented2 = transform(data)\n",
        "\n",
        "                augmented1, augmented2 = augmented1.to(self.device), augmented2.to(self.device)\n",
        "\n",
        "                # Forward pass through encoder and projection head\n",
        "                z1 = model(augmented1)\n",
        "                z2 = model(augmented2)\n",
        "\n",
        "                # Normalized feature vectors\n",
        "                z1 = torch.nn.functional.normalize(z1, dim=1)\n",
        "                z2 = torch.nn.functional.normalize(z2, dim=1)\n",
        "\n",
        "                # Concatenate representations\n",
        "                representations = torch.cat([z1, z2], dim=0)\n",
        "\n",
        "                # Compute similarity matrix\n",
        "                similarity_matrix = torch.matmul(representations, representations.T)\n",
        "\n",
        "                # NT-Xent loss\n",
        "                batch_size = data.size(0)\n",
        "                mask = torch.zeros((2 * batch_size, 2 * batch_size), dtype=bool).to(self.device)\n",
        "\n",
        "                # Set positive pairs\n",
        "                for i in range(batch_size):\n",
        "                    mask[i, batch_size + i] = 1\n",
        "                    mask[batch_size + i, i] = 1\n",
        "\n",
        "                # Remove diagonal (self-similarity)\n",
        "                mask.fill_diagonal_(0)\n",
        "\n",
        "                # Set positive pairs to extremenly high negative value (will be exp(0) = 1)\n",
        "                similarity_matrix = similarity_matrix.masked_fill(~mask, -1e9)\n",
        "\n",
        "                # Compute NT-Xent loss\n",
        "                logits = similarity_matrix / temperature\n",
        "                labels = torch.arange(2 * batch_size).to(self.device)\n",
        "                loss = torch.nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "                # Optimization step\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                if batch_idx % 10 == 0:\n",
        "                    logger.info(f\"SimCLR Training: Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            logger.info(f\"SimCLR Epoch {epoch+1}/{epochs}: Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        logger.info(\"SimCLR pre-training completed\")"
      ],
      "metadata": {
        "id": "hmeampkjFQbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_vbl_va001_dataset(download_path: str = './data'):\n",
        "    \"\"\"Download VBL-VA001 dataset from Zenodo.\"\"\"\n",
        "    try:\n",
        "        # Create download directory if it doesn't exist\n",
        "        os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "        # Zenodo URL for the VBL-VA001 dataset\n",
        "        zenodo_url = \"https://zenodo.org/records/7006575/files/VBL-VA001.zip\"\n",
        "\n",
        "        logger.info(f\"Downloading VBL-VA001 dataset from {zenodo_url}\")\n",
        "        logger.info(\"This may take some time depending on your internet connection...\")\n",
        "\n",
        "        # Download the file\n",
        "        response = requests.get(zenodo_url, stream=True)\n",
        "        response.raise_for_status()  # Raise exception for HTTP errors\n",
        "\n",
        "        # Check if the zip file already exists\n",
        "        zip_path = os.path.join(download_path, \"VBL-VA001.zip\")\n",
        "        extract_path = os.path.join(download_path, \"VBL-VA001\")\n",
        "\n",
        "        # Write the content to a zip file\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        logger.info(f\"Download completed to {zip_path}\")\n",
        "\n",
        "        # Extract the zip file\n",
        "        logger.info(f\"Extracting dataset to {extract_path}\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(download_path)\n",
        "\n",
        "        logger.info(f\"Dataset extracted successfully to {extract_path}\")\n",
        "        return extract_path\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logger.error(f\"Error downloading dataset: {str(e)}\")\n",
        "        return None\n",
        "    except zipfile.BadZipFile as e:\n",
        "        logger.error(f\"Error extracting dataset: {str(e)}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unexpected error: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ssHYN_-uFQQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "    try:\n",
        "        # Set configuration parameters\n",
        "        config = {\n",
        "            'learning_rate': 0.001,\n",
        "            'batch_size': 32,\n",
        "            'epochs': 50,\n",
        "            'use_model_agent': True,\n",
        "            'use_simclr': True,\n",
        "            'test_split': 0.2,\n",
        "            'val_split': 0.1\n",
        "        }\n",
        "\n",
        "        # Download and extract dataset if needed\n",
        "        data_path = './data/VBL-VA001'\n",
        "        if not os.path.exists(data_path):\n",
        "            logger.info(\"Dataset not found locally. Downloading...\")\n",
        "            data_path = download_vbl_va001_dataset()\n",
        "            if data_path is None:\n",
        "                logger.error(\"Failed to download dataset. Exiting.\")\n",
        "                return\n",
        "\n",
        "        # Define transformations\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "        ])\n",
        "\n",
        "        # Load dataset\n",
        "        logger.info(f\"Loading dataset from {data_path}\")\n",
        "        try:\n",
        "            full_dataset = VBLVA001Dataset(data_path=data_path, transform=transform)\n",
        "            logger.info(f\"Dataset loaded with {len(full_dataset)} samples and {full_dataset.num_classes} classes\")\n",
        "\n",
        "            # Split dataset into train, validation, and test\n",
        "            dataset_size = len(full_dataset)\n",
        "            test_size = int(config['test_split'] * dataset_size)\n",
        "            val_size = int(config['val_split'] * dataset_size)\n",
        "            train_size = dataset_size - test_size - val_size\n",
        "\n",
        "            train_dataset, val_dataset, test_dataset = random_split(\n",
        "                full_dataset, [train_size, val_size, test_size],\n",
        "                generator=torch.Generator().manual_seed(42)\n",
        "            )\n",
        "\n",
        "            # Create data loaders\n",
        "            train_loader = DataLoader(\n",
        "                train_dataset,\n",
        "                batch_size=config['batch_size'],\n",
        "                shuffle=True,\n",
        "                num_workers=4,\n",
        "                pin_memory=True\n",
        "            )\n",
        "\n",
        "            val_loader = DataLoader(\n",
        "                val_dataset,\n",
        "                batch_size=config['batch_size'],\n",
        "                shuffle=False,\n",
        "                num_workers=4,\n",
        "                pin_memory=True\n",
        "            )\n",
        "\n",
        "            test_loader = DataLoader(\n",
        "                test_dataset,\n",
        "                batch_size=config['batch_size'],\n",
        "                shuffle=False,\n",
        "                num_workers=4,\n",
        "                pin_memory=True\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Data split: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
        "\n",
        "            # Initialize and train the model\n",
        "            analyzer = VibrationAnalyzer(config)\n",
        "\n",
        "            # Train SimCLR model first if enabled\n",
        "            if config['use_simclr'] and hasattr(analyzer, 'train_simclr'):\n",
        "                logger.info(\"Starting self-supervised pre-training with SimCLR\")\n",
        "                analyzer.train_simclr(train_loader)\n",
        "\n",
        "            # Train the main model\n",
        "            logger.info(\"Starting supervised training\")\n",
        "            analyzer.train(\n",
        "                train_loader=train_loader,\n",
        "                val_loader=val_loader,\n",
        "                num_classes=full_dataset.num_classes,\n",
        "                label_mapping=full_dataset.label_mapping\n",
        "            )\n",
        "\n",
        "            # Evaluate model\n",
        "            logger.info(\"Evaluating model on test set\")\n",
        "            analyzer.evaluate(test_loader, full_dataset.num_classes)\n",
        "\n",
        "            # Plot metrics\n",
        "            analyzer.plot_metrics()\n",
        "\n",
        "            logger.info(\"Training and evaluation completed successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in main execution: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unhandled exception in main: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "wrjqrIFWGPFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_sample(dataset_path, sample_idx=0):\n",
        "    \"\"\"Visualize a sample from the dataset.\"\"\"\n",
        "    try:\n",
        "        # Load dataset\n",
        "        dataset = VBLVA001Dataset(data_path=dataset_path)\n",
        "\n",
        "        if sample_idx >= len(dataset):\n",
        "            logger.error(f\"Sample index {sample_idx} out of range (0-{len(dataset)-1})\")\n",
        "            return\n",
        "\n",
        "        # Get sample data\n",
        "        spectrogram, label = dataset[sample_idx]\n",
        "        raw_signal = dataset.data[sample_idx]\n",
        "\n",
        "        # Convert label to class name\n",
        "        class_name = dataset.label_mapping.get(label, f\"Unknown ({label})\")\n",
        "\n",
        "        # Create figure with multiple plots\n",
        "        fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
        "\n",
        "        # Plot raw signal\n",
        "        axes[0].plot(raw_signal)\n",
        "        axes[0].set_title(f\"Raw Vibration Signal - Class: {class_name}\")\n",
        "        axes[0].set_xlabel(\"Sample\")\n",
        "        axes[0].set_ylabel(\"Amplitude\")\n",
        "\n",
        "        # Plot denoised signal\n",
        "        denoised = dataset.preprocessor.remove_noise(raw_signal)\n",
        "        axes[1].plot(denoised)\n",
        "        axes[1].set_title(\"Denoised Signal\")\n",
        "        axes[1].set_xlabel(\"Sample\")\n",
        "        axes[1].set_ylabel(\"Amplitude\")\n",
        "\n",
        "        # Plot spectrogram\n",
        "        spectrogram = spectrogram.squeeze().numpy()\n",
        "        im = axes[2].imshow(spectrogram, aspect='auto', origin='lower', cmap='viridis')\n",
        "        axes[2].set_title(\"Spectrogram\")\n",
        "        axes[2].set_xlabel(\"Time\")\n",
        "        axes[2].set_ylabel(\"Frequency\")\n",
        "        plt.colorbar(im, ax=axes[2])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"sample_{sample_idx}_visualization.png\")\n",
        "        plt.show()\n",
        "\n",
        "        logger.info(f\"Sample {sample_idx} visualization saved to sample_{sample_idx}_visualization.png\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error visualizing sample: {str(e)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hDUNBzSgGPCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv-Iif_QGO_p",
        "outputId": "d74a4c08-0b5e-4d8f-d6da-4bd36ac93e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "ERROR:__main__:Error during epoch 0: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 1: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 2: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 3: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 4: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 5: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 6: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 7: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 8: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 9: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 10: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 11: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 12: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 13: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 14: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 15: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 16: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 17: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 18: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 19: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 20: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 21: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 22: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 23: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 24: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 25: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 26: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 27: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 28: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 29: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 30: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 31: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 32: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 33: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 34: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 35: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 36: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 37: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 38: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 39: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 40: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 41: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 42: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 43: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 44: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 45: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 46: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 47: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 48: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:Error during epoch 49: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-11-0b80e77870ff>\", line 107, in train\n",
            "    val_metrics = self._validate(self.model, val_loader, criterion)\n",
            "                  ^^^^^^^^^^^^^^\n",
            "AttributeError: 'VibrationAnalyzer' object has no attribute '_validate'\n",
            "ERROR:__main__:No metrics to plot. Train the model first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     bearing       1.00      1.00      1.00        10\n",
            "misalignment       0.60      1.00      0.75         9\n",
            "      normal       1.00      1.00      1.00         7\n",
            "   unbalance       1.00      0.57      0.73        14\n",
            "\n",
            "    accuracy                           0.85        40\n",
            "   macro avg       0.90      0.89      0.87        40\n",
            "weighted avg       0.91      0.85      0.85        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FdIlSAPGO8x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}